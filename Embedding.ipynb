{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a191446",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Simple example of word embeedings  ##########################\n",
    "# It takes 4 words and gets thes embeddings (w1, w2) as it 2d representation #\n",
    "##############################################################################\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b21825",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(298630698)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca858935",
   "metadata": {},
   "outputs": [],
   "source": [
    "words =[\"Troll\",\"is\", \"great\",\"Gymkata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172045c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "L = [\"Troll is great\\n\", \"Gymkata is great\\n\", \"Sam is fat and heavy\\n\", \"Sam is great\\n\",\"Dali is small\\n\",\"Gymkata is fat\\n\",\n",
    "     \"Dali is great\\n\", \"Dali is a bit small\\n\",\"Sam and Dali are heavy\\n\"]\n",
    "dictionary=set()\n",
    "# writing to file\n",
    "file1 = open('myfile.txt', 'w')\n",
    "file1.writelines(L)\n",
    "file1.close()\n",
    " \n",
    "# Using readlines()\n",
    "file1 = open('myfile.txt', 'r')\n",
    "file1 = open('texto3.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    " \n",
    "count = 0\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    count += 1\n",
    "    print(\"Line {}: {}\".format(count, line.strip()))\n",
    "    # using split() method with a regular expression\n",
    "    # to extract words from string\n",
    "    res = re.split(r'\\W+', line.strip())\n",
    "    words = []\n",
    "    for word in res:\n",
    "        if word:\n",
    "            words.append(word)\n",
    "    for word in words:\n",
    "        #print(word)\n",
    "        dictionary.add(word)\n",
    "print(dictionary)\n",
    "classes= len(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = (dictionary)\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f6222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=[]\n",
    "ys=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c9555",
   "metadata": {},
   "outputs": [],
   "source": [
    "g=[]\n",
    "i=0\n",
    "for line in Lines:\n",
    "    print(\"frase \",end=\"\")\n",
    "    print(i,\": \",line)\n",
    "    \n",
    "    for w in line.split():\n",
    "     #   print(\"2 \",w)\n",
    "        g.append(w)\n",
    "    for j,l in zip(g,g[1:]):\n",
    "        print(j,l)\n",
    "        ix1 = stoi[j]\n",
    "        ix2 = stoi[l]\n",
    "        #print(ix1, ix2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "    i=i+1\n",
    "    g=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad17a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xs, ys = [], []\n",
    "#for line in Lines:\n",
    "#    for j,l in zip(line,line[1:]):\n",
    "#        print(j,l)\n",
    "#        ix1 = stoi[j]\n",
    "#        ix2 = stoi[l]\n",
    "#        print(ix1, ix2)\n",
    "#        xs.append(ix1)\n",
    "#        ys.append(ix2)\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be22308",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs=xs-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1664b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys=ys-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe93cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenc = F.one_hot(xs, num_classes=classes).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13327f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yenc = F.one_hot(ys, num_classes=classes).float()\n",
    "yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  xenc #torch.tensor(((1,0,0,0,0),(0,1,0,0,0),(0,0,1,0,0),(0,0,0,1,0),(0,0,0,0,1)),requires_grad=False,dtype=torch.float32)\n",
    "w1 = torch.randn((classes,2),requires_grad=True,dtype=torch.float32)\n",
    "w2 = torch.randn((2,classes),requires_grad=True,dtype=torch.float32)\n",
    "y =  yenc #torch.tensor(((0,1,0,0,0),(0,0,1,0,0),(0,0,0,1,0),(0,1,0,0,0),(0,1,0,0,0)) ,requires_grad=False,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c72d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.tensor(((1,0,0,0),(0,1,0,0),(0,0,1,0),(0,0,0,1)),requires_grad=False,dtype=torch.float32)\n",
    "#w1 = torch.randn((4,2),requires_grad=True,dtype=torch.float32)\n",
    "#w2 = torch.randn((2,4),requires_grad=True,dtype=torch.float32)\n",
    "#y = torch.tensor(((0,1,0,0),(0,0,1,0),(0,0,0,1),(0,1,0,0)) ,requires_grad=False,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25623b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to(\"cuda:0\")\n",
    "w1.to(\"cuda:0\")\n",
    "w2.to(\"cuda:0\")\n",
    "y.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb211562",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18531c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.retain_grad()\n",
    "w2.retain_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65b3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range (3000):\n",
    "    z1= x@ w1\n",
    "    z2= z1 @ w2\n",
    "    f= torch.softmax(z2,dim=1)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    w1.grad=None\n",
    "    w2.grad =None\n",
    "    r=0.1\n",
    "    output = loss(f, y)\n",
    "    output.backward()\n",
    "    w1.data+=-r*w1.grad\n",
    "    w2.data+=-r*w2.grad\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f5db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1= x@ w1\n",
    "z2= z1 @ w2\n",
    "f= torch.softmax(z2,dim=1)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc038d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=list(x[0])\n",
    "max_value = max(p)\n",
    "max_index = p.index(max_value)\n",
    "itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2961d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(15):\n",
    "    s=list(f[h])\n",
    "    max_value = max(s)\n",
    "    max_index = s.index(max_value)\n",
    "    print(itos[max_index+1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e032d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = w1.tolist()\n",
    "x1,y1 =list(zip(*d))\n",
    "plt.scatter(x1,y1)\n",
    "for i, txt in enumerate(dictionary):\n",
    "    plt.annotate(txt, (x1[i], y1[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce62362",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ffcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(w1.detach().numpy(), color='blue')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fadb6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65041fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.']=0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size=3\n",
    "context=[0]*block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fcab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = [],[]\n",
    "for w in words:\n",
    "    #print(\"word: \",w)\n",
    "    for ch in w+'.':\n",
    "        #print(\"char: \",ch)\n",
    "        ix= stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        #print(''.join(itos[i] for i in context) ,\"---->\", itos[ix])\n",
    "        context = context[1:] +[ix]\n",
    "\n",
    "X=torch.tensor(X)\n",
    "Y=torch.tensor(Y)\n",
    "\n",
    "                                                            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587105cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da630ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4cd62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd01250",
   "metadata": {},
   "outputs": [],
   "source": [
    "g= torch.Generator().manual_seed(2147483647)\n",
    "C= torch.rand((27,2),generator=g)\n",
    "W1= torch.rand(6,100,generator=g)\n",
    "b1 = torch.rand(100,generator=g)\n",
    "W2 = torch.randn((100,27),generator=g)\n",
    "b2 = torch.randn(27,generator=g)\n",
    "parameters =[C,W1,b1,W2,b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84149034",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C.to(\"cuda:0\")\n",
    "W1.to(\"cuda:0\")\n",
    "b1.to(\"cuda:0\")\n",
    "W2.to(\"cuda:0\")\n",
    "b2.to(\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614024f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d6ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84999e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    emb= C[X]\n",
    "    h=torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
    "    logits = h @ W2+ b2\n",
    "    loss= F.cross_entropy(logits,Y)\n",
    "    print(loss.item())\n",
    "    for p in parameters:\n",
    "            p.grad= None\n",
    "    loss.backward()\n",
    "    for p in parameters:\n",
    "        p.data = p.data -0.1* p.grad\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e139f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data,C[:,1].data,s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(),C[i,1].item(),itos[i],color='white',ha='center',va='center')\n",
    "plt.grid('minor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a05f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    out=[]\n",
    "    context = [0]*block_size\n",
    "    while True:\n",
    "        emb=C[torch.tensor([context])]\n",
    "        h= torch.tanh(emb.view(1,-1) @ W1+b1)\n",
    "        logits = h@W2 +b2\n",
    "        probs = F.softmax(logits,dim=1)\n",
    "        ix= torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:]+[ix]\n",
    "        out.append(ix)\n",
    "        if ix==0:\n",
    "            break\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6cbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### GPT #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b497243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1469606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc73705",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"input.txt\").read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baedbd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = list(sorted(set(text)))\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ed743",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enumerate(chars):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215f6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda word:    [stoi[ch] for ch in word]\n",
    "decode = lambda entero:  ''.join([itos[i] for i in entero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encode(\"perro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decode(encode(\"perro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= torch.tensor(encode(text),dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb89758",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db722067",
   "metadata": {},
   "outputs": [],
   "source": [
    "n= int(0.9*len(data))\n",
    "train_data= data[:n]\n",
    "val_data= data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62acef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size=8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f44f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train_data[:block_size]\n",
    "y=train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context= x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when the input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9042361",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data= train_data if split==\"train\" else val_data\n",
    "    ix= torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "                \n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when the input is {context} the target is {target}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada00b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Embedding ############\n",
    "import torch \n",
    "from torch.nn import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embeddings,dim = 10,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca296047",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1 = Embedding(n_embeddings, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9473d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = torch.LongTensor([[1,3],[5,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79054da",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "973dba08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2c73bc85f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f4d7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "312c1822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519],\n",
       "        [-0.1661, -1.5228,  0.3817, -1.0276, -0.5631]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4479c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hola():\n",
    "    def __init__(self,v):\n",
    "        self.vocal=v\n",
    "    \n",
    "    def forward(self,idx):\n",
    "        return \"aa\"\n",
    "        \n",
    "    def forward1(self,idx):\n",
    "        return \"holaa\"\n",
    "    \n",
    "    def generate(self,idx):\n",
    "        f=self(idx)\n",
    "        return \"3\"+f\n",
    "    \n",
    "\n",
    "d=hola(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4fa7e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'hola' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43md\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mhola.generate\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m,idx):\n\u001b[0;32m---> 12\u001b[0m     f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mf\n",
      "\u001b[0;31mTypeError\u001b[0m: 'hola' object is not callable"
     ]
    }
   ],
   "source": [
    "d.generate(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e446b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1101],\n",
       "        [-0.1957]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class myLayer(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Linear(10,1)\n",
    "  def forward(self, input_tensor):\n",
    "    return self.layer1(input_tensor)\n",
    "model = myLayer()\n",
    "input_tensor = torch.rand((2,10))\n",
    "#//treat as callable, which is same as model.forward(tensor)\n",
    "model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Conditional probaility########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13906e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169efb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 :  5\n",
      " 5 :  2\n",
      " 3 :  3\n",
      " 4 :  3\n",
      " 2 :  4\n"
     ]
    }
   ],
   "source": [
    "def CountFrequency(my_list):\n",
    "\n",
    "\t# Creating an empty dictionary\n",
    "\tfreq = {}\n",
    "\tfor item in my_list:\n",
    "\t\tif (item in freq):\n",
    "\t\t\tfreq[item] += 1\n",
    "\t\telse:\n",
    "\t\t\tfreq[item] = 1\n",
    "\n",
    "\tfor key, value in freq.items():\n",
    "\t\tprint(\"% d : % d\" % (key, value))\n",
    "\n",
    "\n",
    "# Driver function\n",
    "if __name__ == \"__main__\":\n",
    "\tmy_list = [1, 1, 1, 5, 5, 3, 1, 3, 3, 1, 4, 4, 4, 2, 2, 2, 2]\n",
    "\n",
    "\tCountFrequency(my_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3067f613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: Roger is young\n",
      "Line 2: Dali is a dog\n",
      "Line 3: Dakota is old\n",
      "Line 4: Roger is funny\n",
      "Line 5: Marta is small\n",
      "Line 6: Magce is fat\n",
      "Line 7: Julia is white\n",
      "Line 8: Julia is working\n",
      "Line 9: Roger sleeps late\n",
      "Line 10: Roger is happy\n",
      "Line 11: NEC is a company\n",
      "Line 12: Huawei is a company\n",
      "Line 13: Nokia is a company\n",
      "Line 14: Dakota is a dog\n",
      "Line 15: Marta is a woman\n",
      "Line 16: Magce is a woman\n",
      "Line 17: Marta is black\n",
      "{'dog', 'Dakota', 'NEC', 'funny', 'young', 'happy', 'Nokia', 'a', 'is', 'Marta', 'sleeps', 'fat', 'company', 'white', 'black', 'Magce', 'working', 'late', 'woman', 'old', 'Huawei', 'Julia', 'Dali', 'small', 'Roger'}\n"
     ]
    }
   ],
   "source": [
    "conjunto =set()\n",
    "file1 = open('texto3.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    " \n",
    "count = 0\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    count += 1\n",
    "    print(\"Line {}: {}\".format(count, line.strip()))\n",
    "    res = re.split(r'\\W+', line.strip())\n",
    "    words = []\n",
    "    for word in res:\n",
    "        if word:\n",
    "            words.append(word)\n",
    "    for word in words:\n",
    "        #print(word)\n",
    "        conjunto.add(word)\n",
    "print(conjunto)\n",
    "classes= len(conjunto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440de9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab87fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
